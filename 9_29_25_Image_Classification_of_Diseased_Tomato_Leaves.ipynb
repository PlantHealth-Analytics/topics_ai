{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2c4a966-4298-4642-8aac-bf95a0e955d0",
      "metadata": {
        "id": "a2c4a966-4298-4642-8aac-bf95a0e955d0"
      },
      "source": [
        "# Disease detection from images using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f95a058-5589-46d6-a04d-900952cf3550",
      "metadata": {
        "id": "6f95a058-5589-46d6-a04d-900952cf3550"
      },
      "source": [
        "The data set was retrieved from [Plant Village on Kaggle](https://www.kaggle.com/datasets/emmarex/plantdisease)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd55c9b0-4841-4e25-a0ce-5915b9777642",
      "metadata": {
        "id": "dd55c9b0-4841-4e25-a0ce-5915b9777642"
      },
      "outputs": [],
      "source": [
        "# CELL 1\n",
        "#Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LqxQLYbS_vHy",
      "metadata": {
        "id": "LqxQLYbS_vHy"
      },
      "outputs": [],
      "source": [
        "#CELL 2\n",
        "!gdown --id 1NpuJFX3XqOVE69sO4OXKERgy8jueTXrO --output data.zip\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4af44098-e18d-4b60-aa0e-335a4998b2ad",
      "metadata": {
        "id": "4af44098-e18d-4b60-aa0e-335a4998b2ad"
      },
      "outputs": [],
      "source": [
        "#CELL 3\n",
        "# Define image dimensions\n",
        "img_width, img_height = 150, 150\n",
        "target_size = (img_width, img_height)\n",
        "batch_size = 32\n",
        "\n",
        "# Set directories\n",
        "train_dir = '/content/train'\n",
        "validation_dir = '/content/validation'\n",
        "\n",
        "# Data augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,            # Rescale pixel values from [0, 255] to [0, 1]\n",
        "    rotation_range=40,         # Random rotation between 0 and 40 degrees\n",
        "    width_shift_range=0.2,     # Random horizontal shift\n",
        "    height_shift_range=0.2,    # Random vertical shift\n",
        "    shear_range=0.2,           # Shear transformations\n",
        "    zoom_range=0.2,            # Zoom in/out\n",
        "    horizontal_flip=True,      # Randomly flip images horizontally\n",
        "    fill_mode='nearest'        # Fill in missing pixels after transformations\n",
        ")\n",
        "\n",
        "# Validation data should not be augmented\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'  # Since it's a binary classification problem\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important to keep data in the same order for evaluation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f11b30f-09bf-4187-a254-bbe99132a7eb",
      "metadata": {
        "id": "4f11b30f-09bf-4187-a254-bbe99132a7eb"
      },
      "outputs": [],
      "source": [
        "#CELL 4\n",
        "# Visualize some healthy and diseased images\n",
        "def plot_sample_images(generator, class_names, title):\n",
        "    x_batch, y_batch = next(generator)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(x_batch[i])\n",
        "        class_idx = int(y_batch[i])\n",
        "        plt.title(class_names[class_idx])\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Get class indices\n",
        "class_indices = train_generator.class_indices\n",
        "# Mapping from class index to class label\n",
        "class_names = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# Plot sample images from training data\n",
        "plot_sample_images(train_generator, class_names, 'Sample Training Images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5159a0e4-b2bf-49b9-b5f2-39e94f086ee5",
      "metadata": {
        "id": "5159a0e4-b2bf-49b9-b5f2-39e94f086ee5"
      },
      "outputs": [],
      "source": [
        "#CELL 5\n",
        "# Initialize the model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# View model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CELL 6\n",
        "# --------------------------------------------------\n",
        "# Configure training\n",
        "# --------------------------------------------------\n",
        "# @title 🚀 Training settings\n",
        "EPOCHS = 10  # @param {type:\"slider\", min:1, max:50, step:1}\n",
        "print(f\"Training for {EPOCHS} epoch(s)…\")"
      ],
      "metadata": {
        "id": "RX0fFfxgy00K",
        "outputId": "fb0b65ff-37fa-4066-a5e3-cc39fd270543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "RX0fFfxgy00K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50 epoch(s)…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1f521fe-9077-488c-9f26-59f3f9f04bba",
      "metadata": {
        "id": "a1f521fe-9077-488c-9f26-59f3f9f04bba"
      },
      "outputs": [],
      "source": [
        "# CELL 7\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cf496d-6bab-4087-a0da-bf27286c8d77",
      "metadata": {
        "id": "23cf496d-6bab-4087-a0da-bf27286c8d77"
      },
      "outputs": [],
      "source": [
        "# CELL 8\n",
        "# Plot training & validation accuracy/loss\n",
        "def plot_training_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f75bad-696b-4fd1-a6d4-3c875e44f377",
      "metadata": {
        "id": "39f75bad-696b-4fd1-a6d4-3c875e44f377"
      },
      "outputs": [],
      "source": [
        "# CELL 9\n",
        "# Evaluate on validation data\n",
        "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
        "print(f'Test loss: {validation_loss}')\n",
        "print(f'Test accuracy: {validation_accuracy}')\n",
        "\n",
        "# Make predictions on validation data\n",
        "validation_generator.reset()  # Reset the generator\n",
        "predictions = model.predict(validation_generator, steps=validation_generator.samples // batch_size + 1)\n",
        "predicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = validation_generator.classes\n",
        "class_labels = list(validation_generator.class_indices.keys())\n",
        "\n",
        "# Identify correctly and incorrectly classified images\n",
        "correct = np.where(predicted_classes == true_classes)[0]\n",
        "incorrect = np.where(predicted_classes != true_classes)[0]\n",
        "\n",
        "# Function to plot images\n",
        "def plot_images(indices, generator, title):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i, idx in enumerate(indices[:9]):  # Plot up to 9 images\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        img_path = validation_generator.filepaths[idx]\n",
        "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "        plt.imshow(img_array)\n",
        "        pred_label = class_names[predicted_classes[idx]]\n",
        "        true_label = class_names[true_classes[idx]]\n",
        "        plt.title(f'True: {true_label}\\nPredicted: {pred_label}')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Plot some correctly classified images\n",
        "plot_images(correct, validation_generator, 'Correctly Classified Images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "577377e6-bd11-444a-b31e-18adf83df511",
      "metadata": {
        "id": "577377e6-bd11-444a-b31e-18adf83df511"
      },
      "outputs": [],
      "source": [
        "# CELL 10\n",
        "# Plot some incorrectly classified images\n",
        "plot_images(incorrect, validation_generator, 'Incorrectly Classified Images')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73e59ce5-e3b7-47fd-8384-16150cc838eb",
      "metadata": {
        "id": "73e59ce5-e3b7-47fd-8384-16150cc838eb"
      },
      "source": [
        "### Hands-On Section: Choosing the Number of Epochs\n",
        "\n",
        "The notebook begins with 10 Epochs. Pick several Epochs to improve the performance of the model on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test your model!\n",
        "\n",
        "Upload a leaf photo and get a prediction"
      ],
      "metadata": {
        "id": "gcEhpuy92BFQ"
      },
      "id": "gcEhpuy92BFQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11\n",
        "# --------------------------------------------------\n",
        "# 🔍 Upload your own leaf image and predict\n",
        "# --------------------------------------------------\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "\n",
        "# 1. Upload\n",
        "print(\"Select a JPG/PNG of a single leaf…\")\n",
        "uploaded = files.upload()   # opens a file-picker in the browser\n",
        "\n",
        "# 2. Pre-process & predict\n",
        "for fname in uploaded.keys():\n",
        "    # Load -> resize -> scale\n",
        "    img = keras_image.load_img(fname, target_size=target_size)\n",
        "    img_arr = keras_image.img_to_array(img) / 255.0\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)           # shape (1, H, W, 3)\n",
        "\n",
        "    # Predict\n",
        "    score = model.predict(img_arr)[0][0]                # sigmoid output\n",
        "    label = \"Diseased\" if score > 0.5 else \"Healthy\"\n",
        "\n",
        "    # 3. Show result\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Predicted: {label}  (score={score:.2f})\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4ZdsMmlS2DTd"
      },
      "id": "4ZdsMmlS2DTd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Tensorflow-2.7.0",
      "language": "python",
      "name": "tensorflow-2.7.0"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}